{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"question_answering_albert.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"74df97d012944f92a0f14959fab487d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_889b29687c1a467dbaa54f29b92fb47b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f2471c334fa45989c3b9cba73c33738","IPY_MODEL_b8356b36141348669829a66f36956678","IPY_MODEL_8f5e007ab3014c7dafb5c836fc5fca11"]}},"889b29687c1a467dbaa54f29b92fb47b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f2471c334fa45989c3b9cba73c33738":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5d04ea7147454f45abb8b67739cf954b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c35805dd01d44c3813b70c9ae3f626c"}},"b8356b36141348669829a66f36956678":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a7f6894f77de48748aabc4e9f30a9078","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8760f5a112344e12a81ea0e8981c238f"}},"8f5e007ab3014c7dafb5c836fc5fca11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_921cc87f9bcf4ca6a17abff7d07298a8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:00&lt;00:00,  6.43it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_392042091c624c3f8cb13ed2a4713079"}},"5d04ea7147454f45abb8b67739cf954b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1c35805dd01d44c3813b70c9ae3f626c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7f6894f77de48748aabc4e9f30a9078":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8760f5a112344e12a81ea0e8981c238f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"921cc87f9bcf4ca6a17abff7d07298a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"392042091c624c3f8cb13ed2a4713079":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"X4cRE8IbIrIV"},"source":["If you're opening this Notebook on colab, you will probably need to install ðŸ¤— Transformers and ðŸ¤— Datasets. Uncomment the following cell and run it."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ZqeuMMjbis9","executionInfo":{"status":"ok","timestamp":1639367748985,"user_tz":300,"elapsed":3688,"user":{"displayName":"Julsoles","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQsyPnEHtcIJ8Tllqntz58p0iz1ENQv8ftkloycg=s64","userId":"05704841641291254475"}},"outputId":"40c671ef-da50-4e6e-d526-9762510fa6a2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"Uafo0W_ucr_-"},"source":["import os\n","#os.chdir('/content/drive/MyDrive/HES/NLP Final Project')\n","os.chdir('/content/drive/MyDrive/115_experimentation/NLP Final Project')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOsHUjgdIrIW","executionInfo":{"status":"ok","timestamp":1639367752986,"user_tz":300,"elapsed":4004,"user":{"displayName":"Julsoles","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQsyPnEHtcIJ8Tllqntz58p0iz1ENQv8ftkloycg=s64","userId":"05704841641291254475"}},"outputId":"a81e8477-346a-4cc2-8197-97c3e86f24fb"},"source":["!pip install datasets[s3] transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets[s3] in /usr/local/lib/python3.7/dist-packages (1.16.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.13.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets[s3]) (3.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets[s3]) (3.8.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets[s3]) (0.3.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets[s3]) (2.0.2)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets[s3]) (2021.11.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets[s3]) (0.70.12.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets[s3]) (1.1.5)\n","Requirement already satisfied: botocore in /usr/local/lib/python3.7/dist-packages (from datasets[s3]) (1.23.23)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from datasets[s3]) (1.20.23)\n","Requirement already satisfied: s3fs in /usr/local/lib/python3.7/dist-packages (from datasets[s3]) (0.4.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets[s3]) (21.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets[s3]) (1.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets[s3]) (1.7.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets[s3]) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets[s3]) (0.13.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets[s3]) (4.0.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets[s3]) (2.0.8)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets[s3]) (5.2.0)\n","Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->datasets[s3]) (0.5.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->datasets[s3]) (0.10.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore->datasets[s3]) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore->datasets[s3]) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets[s3]) (2018.9)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"]}]},{"cell_type":"code","source":["!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n","!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n","!pip install torch-geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hclY8bvigmv","executionInfo":{"status":"ok","timestamp":1639367761305,"user_tz":300,"elapsed":8322,"user":{"displayName":"Julsoles","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQsyPnEHtcIJ8Tllqntz58p0iz1ENQv8ftkloycg=s64","userId":"05704841641291254475"}},"outputId":"7acc94ee-c9f7-4681-b919-e68d0b1bf6d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n","Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n","Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n","Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.12)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.0)\n","Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n","Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n","Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.0.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n","Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"rr9xcoVQoFbp"},"source":["If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n","\n","To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\n","\n","First you have to store your authentication token from the Hugging Face website (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your username and password:"]},{"cell_type":"markdown","metadata":{"id":"mQbjvvFFoFbq"},"source":["Then you need to install Git-LFS. Uncomment the following instructions:"]},{"cell_type":"markdown","metadata":{"id":"htNaJbDCoFbr"},"source":["Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Bhysz0-oFbr","executionInfo":{"status":"ok","timestamp":1639367771136,"user_tz":300,"elapsed":9834,"user":{"displayName":"Julsoles","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQsyPnEHtcIJ8Tllqntz58p0iz1ENQv8ftkloycg=s64","userId":"05704841641291254475"}},"outputId":"5e4e8bec-7c21-4686-96a2-001fd8721c69"},"source":["import transformers\n","import pickle\n","import re\n","import spacy\n","from collections import deque\n","import networkx as nx\n","import pandas as pd\n","import numpy as np\n","from datasets import ClassLabel, Sequence\n","import random\n","import pandas as pd\n","\n","import transformers\n","import dask.dataframe as dd\n","import pickle\n","import re\n","import spacy\n","from collections import deque\n","import networkx as nx\n","import torch\n","from torch import nn\n","from torch import nn, optim, Tensor\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer, AutoModel\n","from transformers.modeling_outputs import QuestionAnsweringModelOutput\n","from tqdm import tqdm\n","print(transformers.__version__)\n","print(transformers.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4.13.0\n","4.13.0\n"]}]},{"cell_type":"code","metadata":{"id":"ce9VuXSsiEu8"},"source":["# https://stackoverflow.com/questions/517923/what-is-the-best-way-to-remove-accents-normalize-in-a-python-unicode-string\n","# function to remove accent from Emglish words\n","import unicodedata\n","def strip_accents(s):\n","   return ''.join(c for c in unicodedata.normalize('NFD', s)\n","                  if unicodedata.category(c) != 'Mn')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qflvjehF1JxM"},"source":["# upload ConceptNet English data\n","cnet_df = pd.read_csv('data/cnet_en_encoded.csv')\n","cnet_word_set = set(cnet_df[['source', 'target']].values.flatten())\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5S7KJOCv7LkS"},"source":["import unicodedata\n","def strip_accents(s):\n","   return ''.join(c for c in unicodedata.normalize('NFD', s)\n","                  if unicodedata.category(c) != 'Mn')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JD3zrh1J1W7z"},"source":["# Upload pre-proccsed data\n","file_name = ['english_words', 'english_word_indices', 'english_embeddings', 'normalized_embeddings', 'word_index']\n","\n","for name in file_name:\n","    with open(f'data/{name}.pickle', 'rb') as pickle_file:\n","        temp = pickle.load(pickle_file)\n","        globals()[name] = temp\n","\n","with open('cnet_embedding_data/conceptnet_ih.graph', 'rb') as pickle_file:\n","    conceptnet = pickle.load(pickle_file)\n","\n","word_embeddings_dict = {key:normalized_embeddings[value] for key,value in word_index.items()}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rEJBSTyZIrIb"},"source":["# Fine-tuning a model on a question-answering task"]},{"cell_type":"code","metadata":{"id":"zVvslsfMIrIh"},"source":["# This flag is the difference between SQUAD v1 or 2 (if you're using another dataset, it indicates if impossible\n","# answers are allowed or not).\n","squad_v2 = True\n","model_checkpoint = 'albert-base-v2'\n","batch_size = 16"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"whPRbBNbIrIl"},"source":["## Loading the dataset"]},{"cell_type":"markdown","metadata":{"id":"W7QYTpxXIrIl"},"source":["We will use the [ðŸ¤— Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "]},{"cell_type":"code","metadata":{"id":"IreSlFmlIrIm"},"source":["\n","from datasets import load_dataset, load_metric"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CKx2zKs5IrIq"},"source":["For our example here, we'll use the [SQUAD dataset](https://rajpurkar.github.io/SQuAD-explorer/). The notebook should work with any question answering dataset provided by the ðŸ¤— Datasets library. If you're using your own dataset defined from a JSON or csv file (see the [Datasets documentation](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files) on how to load them), it might need some adjustments in the names of the columns used."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["74df97d012944f92a0f14959fab487d2","889b29687c1a467dbaa54f29b92fb47b","9f2471c334fa45989c3b9cba73c33738","b8356b36141348669829a66f36956678","8f5e007ab3014c7dafb5c836fc5fca11","5d04ea7147454f45abb8b67739cf954b","1c35805dd01d44c3813b70c9ae3f626c","a7f6894f77de48748aabc4e9f30a9078","8760f5a112344e12a81ea0e8981c238f","921cc87f9bcf4ca6a17abff7d07298a8","392042091c624c3f8cb13ed2a4713079"]},"id":"s_AY1ATSIrIq","executionInfo":{"status":"ok","timestamp":1639367783484,"user_tz":300,"elapsed":866,"user":{"displayName":"Julsoles","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQsyPnEHtcIJ8Tllqntz58p0iz1ENQv8ftkloycg=s64","userId":"05704841641291254475"}},"outputId":"e5d84686-fb93-4418-d817-929a0bc3b3fd"},"source":["datasets = load_dataset(\"squad_v2\" if squad_v2 else \"squad\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Reusing dataset squad_v2 (/root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74df97d012944f92a0f14959fab487d2","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"RzfPtOMoIrIu"},"source":["The `datasets` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set."]},{"cell_type":"code","metadata":{"id":"TZrubCfLcY0o"},"source":["# This flag is the difference between SQUAD v1 or 2 (if you're using another dataset, it indicates if impossible\n","# answers are allowed or not).\n","squad_v2 = True\n","model_checkpoint = 'albert-base-v2'\n","batch_size = 16"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXNLu_-nIrJI"},"source":["from transformers import AutoTokenizer\n","    \n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vl6IidfdIrJK"},"source":["The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the ðŸ¤— Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing."]},{"cell_type":"code","metadata":{"id":"5N1oQKuPoFbz"},"source":["import transformers\n","assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"19w-kId4oFbz"},"source":["You can check which type of models have a fast tokenizer available and which don't on the [big table of models](https://huggingface.co/transformers/index.html#bigtable)."]},{"cell_type":"markdown","metadata":{"id":"rowT4iCLIrJK"},"source":["You can directly call this tokenizer on two sentences (one for the answer, one for the context):"]},{"cell_type":"markdown","metadata":{"id":"bRUxymaEoFb0"},"source":["Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n","\n","Now one specific thing for the preprocessing in question answering is how to deal with very long documents. We usually truncate them in other tasks, when they are longer than the model maximum sentence length, but here, removing part of the the context might result in losing the answer we are looking for. To deal with this, we will allow one (long) example in our dataset to give several input features, each of length shorter than the maximum length of the model (or the one we set as a hyper-parameter). Also, just in case the answer lies at the point we split a long context, we allow some overlap between the features we generate controlled by the hyper-parameter `doc_stride`:"]},{"cell_type":"code","metadata":{"id":"_BG-nZ2goFb0"},"source":["max_length = 384 # The maximum length of a feature (question and context)\n","doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CMlFDV69cmb9"},"source":[""]},{"cell_type":"code","metadata":{"id":"oKMkpphycmb9"},"source":["from transformers import AutoTokenizer\n","    \n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YXhUUsyc2KU"},"source":["pad_on_right = tokenizer.padding_side == \"right\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RntZZ5JvoFb4"},"source":["Now let's put everything together in one function we will apply to our training set. In the case of impossible answers (the answer is in another feature given by an example with a long context), we set the cls index for both the start and end position. We could also simply discard those examples from the training set if the flag `allow_impossible_answers` is `False`. Since the preprocessing is already complex enough as it is, we've kept is simple for this part."]},{"cell_type":"code","metadata":{"id":"lbZ1KbYncPTw"},"source":["# upload ConceptNet English data\n","cnet_df = pd.read_csv('data/cnet_en_encoded.csv')\n","cnet_word_set = set(cnet_df[['source', 'target']].values.flatten())\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uswczMOucPTw"},"source":["import unicodedata\n","def strip_accents(s):\n","   return ''.join(c for c in unicodedata.normalize('NFD', s)\n","                  if unicodedata.category(c) != 'Mn')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IyPhvRA0cPTw"},"source":["\n","# Upload pre-proccsed data\n","file_name = ['english_words', 'english_word_indices', 'english_embeddings', 'normalized_embeddings', 'word_index']\n","\n","for name in file_name:\n","    with open(f'data/{name}.pickle', 'rb') as pickle_file:\n","        temp = pickle.load(pickle_file)\n","        globals()[name] = temp\n","\n","with open('cnet_embedding_data/conceptnet_ih.graph', 'rb') as pickle_file:\n","    conceptnet = pickle.load(pickle_file)\n","\n","word_embeddings_dict = {key:normalized_embeddings[value] for key,value in word_index.items()}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MkuHccaaoFb4"},"source":["pad_on_right = tokenizer.padding_side == \"right\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"62KzG2EXoFb4"},"source":["def extract_graph(initial_set, max_hop = 2):\n","    working_set = initial_set\n","    counter = 0\n","    while counter < max_hop:\n","\n","        node_set = deque(working_set)\n","        m = len(node_set)\n","        working_set = set()\n","        for i in range(m):\n","            node = node_set.pop()\n","            working_set = working_set.union(set(conceptnet.neighbors(node)))\n","        counter += 1\n","        initial_set = initial_set.union(working_set)\n","    return initial_set\n","\n","cashed_stop = nlp.Defaults.stop_words\n","\n","def prepare_train_features(examples):\n","    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n","    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n","    # left whitespace\n","    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n","\n","    # if len(examples[\"question\"]) > 1:\n","    #     raise ValueError(\" number of rows can be at most one\")\n","\n","    reduced_list = [examples[\"context\"][0]]\n","    mapping_dict = {}\n","    j=0\n","    for i, sent_i in enumerate(examples[\"context\"]):\n","        if not sent_i == reduced_list[-1]:\n","            reduced_list.append(sent_i)\n","            j += 1\n","        mapping_dict[i] = j\n","\n","    # working_sentence = [examples[\"question\"][i]+\" \"+examples[\"context\"][i] for i in range(len(examples[\"question\"]))]\n","    working_sentence = [strip_accents(working_sent) for working_sent in reduced_list]\n","    # working_sentence = re.sub('[^A-Za-z0-9 ]+', '', working_sentence)\n","    encoded_docs = [nlp(working_sent) for working_sent in working_sentence]\n","    flatten_set = [{x.text.lower() for x in encoded_doc.ents} for encoded_doc in encoded_docs]\n","    final_list = [{'_'.join([word for word in text.split() if word not in cashed_stop]) for text in word_set} for word_set in flatten_set ]\n","\n","    cnet_set = [{x for x in final_set if x in cnet_word_set and word_index.get(x) is not None} for final_set in final_list]\n","\n","\n","    extracted_list = [extract_graph(initial_set) for initial_set in cnet_set]\n","\n","    #prune the node set\n","    filtered_list = [[ent for ent in initial_set if word_embeddings_dict.get(ent) is not None] for initial_set in extracted_list]\n","\n","    sub_list = [conceptnet.subgraph(filtered_set) for filtered_set in filtered_list]\n","    sub_list = [nx.relabel_nodes(G=sub_cnet, mapping=word_index) for sub_cnet in  sub_list]\n","    adj_df_list = [nx.convert_matrix.to_pandas_edgelist(sub_cnet).values.astype(float) for sub_cnet in  sub_list]\n","\n","\n","\n","    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n","    # in one example possible giving several features when a context is long, each of those features having a\n","    # context that overlaps a bit the context of the previous feature.\n","    tokenized_examples = tokenizer(\n","        examples[\"question\" if pad_on_right else \"context\"],\n","        examples[\"context\" if pad_on_right else \"question\"],\n","        truncation=\"only_second\" if pad_on_right else \"only_first\",\n","        max_length=max_length,\n","        stride=doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","    # todo: extract qa graph:\n","\n","\n","    # Since one example might give us several features if it has a long context, we need a map from a feature to\n","    # its corresponding example. This key gives us just that.\n","    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n","    # The offset mappings will give us a map from token to character position in the original context. This will\n","    # help us compute the start_positions and end_positions.\n","    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n","\n","    # Let's label those examples!\n","    tokenized_examples[\"start_positions\"] = []\n","    tokenized_examples[\"end_positions\"] = []\n","\n","\n","    for i, offsets in enumerate(offset_mapping):\n","        # We will label impossible answers with the index of the CLS token.\n","        input_ids = tokenized_examples[\"input_ids\"][i]\n","        cls_index = input_ids.index(tokenizer.cls_token_id)\n","\n","        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n","        sequence_ids = tokenized_examples.sequence_ids(i)\n","\n","        # One example can give several spans, this is the index of the example containing this span of text.\n","        sample_index = sample_mapping[i]\n","        answers = examples[\"answers\"][sample_index]\n","        # If no answers are given, set the cls_index as answer.\n","        if len(answers[\"answer_start\"]) == 0:\n","            tokenized_examples[\"start_positions\"].append(cls_index)\n","            tokenized_examples[\"end_positions\"].append(cls_index)\n","        else:\n","            # Start/end character index of the answer in the text.\n","            start_char = answers[\"answer_start\"][0]\n","            end_char = start_char + len(answers[\"text\"][0])\n","\n","            # Start token index of the current span in the text.\n","            token_start_index = 0\n","            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n","                token_start_index += 1\n","\n","            # End token index of the current span in the text.\n","            token_end_index = len(input_ids) - 1\n","            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n","                token_end_index -= 1\n","\n","            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n","            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n","                tokenized_examples[\"start_positions\"].append(cls_index)\n","                tokenized_examples[\"end_positions\"].append(cls_index)\n","            else:\n","                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n","                # Note: we could go after the last offset if the answer is the last word (edge case).\n","                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n","                    token_start_index += 1\n","                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n","                while offsets[token_end_index][1] >= end_char:\n","                    token_end_index -= 1\n","                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n","\n","    # data for columns: ['source', 'target', 'code', 'weight']\n","    tokenized_examples['adj_values'] = [adj_df_list[mapping_dict[i]] for i in sample_mapping]\n","\n","\n","    return tokenized_examples"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0lm8ozrJIrJR"},"source":["This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"]},{"cell_type":"markdown","metadata":{"id":"VF90v8InjqfR"},"source":["# Preparing dataset "]},{"cell_type":"code","metadata":{"id":"6WUr05JiEjUA"},"source":["from datasets import load_from_disk\n","loaded_dataset = load_from_disk('tokenized_datasets_batched_small')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PI13EL0dMa6l","executionInfo":{"status":"ok","timestamp":1639367802516,"user_tz":300,"elapsed":6,"user":{"displayName":"Julsoles","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQsyPnEHtcIJ8Tllqntz58p0iz1ENQv8ftkloycg=s64","userId":"05704841641291254475"}},"outputId":"9d430006-4af6-405b-d788-674e2b9d1516"},"source":["loaded_dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['adj_values', 'attention_mask', 'end_positions', 'input_ids', 'start_positions', 'token_type_ids'],\n","        num_rows: 1319\n","    })\n","    validation: Dataset({\n","        features: ['adj_values', 'attention_mask', 'end_positions', 'input_ids', 'start_positions', 'token_type_ids'],\n","        num_rows: 120\n","    })\n","})"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"HTeVAgBzLRNg"},"source":["class SquadDataset(Dataset):\n","    def __init__(self, data):\n","        self.length = len(data)\n","        self.input_ids = data['input_ids']\n","        self.token_type_ids = data['token_type_ids']\n","        self.start_positions = data['start_positions']\n","        self.end_positions = data['end_positions']\n","        self.attention_mask = data['attention_mask']\n","        self.adj_list = data['adj_values']\n","\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, idx: int):\n","\n","        input_ids = self.input_ids[idx]\n","        token_type_ids = self.token_type_ids[idx]\n","        start_positions = self.start_positions[idx]\n","        end_positions = self.end_positions[idx]\n","        attention_mask = self.attention_mask[idx]\n","        adj_list = self.adj_list[idx]\n","\n","        return (torch.tensor(input_ids),\n","                torch.tensor(token_type_ids),\n","                torch.tensor(attention_mask),\n","                torch.from_numpy(np.array(adj_list)),\n","                torch.tensor(start_positions),\n","                torch.tensor(end_positions),\n","                )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7zM1Ib7hMXuk"},"source":["train_ds = SquadDataset(loaded_dataset['train'])\n","\n","def collate_fn(batch):\n","    return tuple(zip(*batch))\n","train_dataloader = DataLoader(train_ds,batch_size=1, shuffle=True, drop_last=False, collate_fn=collate_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader.batch_size"],"metadata":{"id":"CHg-YnwKqUdC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639367957746,"user_tz":300,"elapsed":5,"user":{"displayName":"Julsoles","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQsyPnEHtcIJ8Tllqntz58p0iz1ENQv8ftkloycg=s64","userId":"05704841641291254475"}},"outputId":"4a8b5fb0-0595-44f0-a087-704ce44a3c78"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"sf2U__sqi3Rv"},"source":["val_ds = SquadDataset(loaded_dataset['validation'])\n","val_dataloader = DataLoader(val_ds,batch_size=1, shuffle=True, drop_last=False, collate_fn=collate_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MHwbfS7FMnCT"},"source":["test_batch = next(iter(train_dataloader))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch_geometric.nn import MessagePassing\n","from torch_geometric.utils import add_self_loops, degree, softmax\n","from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool, GlobalAttention, Set2Set, GATConv\n","import torch.nn.functional as F\n","from torch_scatter import scatter_add, scatter\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","\n","class GAT(torch.nn.Module):\n","    def __init__(self, num_features=300, out_dim=768):\n","        super(GAT, self).__init__()\n","        self.hid = 8\n","        self.in_head = 8\n","        self.out_head = 1\n","        self.num_features = num_features\n","        self.out_dim = out_dim\n","        \n","        \n","        self.conv1 = GATConv(self.num_features, self.hid, heads=self.in_head, dropout=0.6)\n","        self.conv2 = GATConv(self.hid*self.in_head, self.out_dim, concat=False,\n","                             heads=self.out_head, dropout=0.6)\n","\n","    def forward(self, x, edge_index):\n","        #x, edge_index = data.x, data.edge_index\n","        \n","        x = F.dropout(x, p=0.6, training=self.training)\n","        #import pdb\n","        #pdb.set_trace()\n","        x = self.conv1(x, edge_index)\n","        x = F.elu(x)\n","        x = F.dropout(x, p=0.6, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        \n","        return F.log_softmax(x, dim=1)"],"metadata":{"id":"vDYQNt-NxyVA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def batch_graph(edge_index_init, edge_type_init, n_nodes):\n","        #edge_index_init: list of (n_examples, ). each entry is torch.tensor(2, E)\n","        #edge_type_init:  list of (n_examples, ). each entry is torch.tensor(E, )\n","    n_examples = len(edge_index_init)\n","    edge_index = [edge_index_init[_i_] + _i_ * n_nodes for _i_ in range(n_examples)]\n","    edge_index = torch.cat(edge_index, dim=1) #[2, total_E]\n","    edge_type = torch.cat(edge_type_init, dim=0) #[total_E, ]\n","    return edge_index, edge_type"],"metadata":{"id":"-K8IXPpAxyXW"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3aasXfGMxsN"},"source":["class AlbertQA(torch.nn.Module):\n","\n","    def __init__(self, gnn_present=False):\n","        super().__init__()\n","\n","        self.lm = AutoModel.from_pretrained(model_checkpoint)\n","        self.lm.resize_token_embeddings(len(tokenizer))\n","        self.gnn_present = gnn_present\n","        self.gnn = GAT() #nn.Linear(self.lm.encoder.config.hidden_size, self.lm.encoder.config.hidden_size)\n","        self.hidden_size = 2*self.lm.encoder.config.hidden_size if gnn_present else self.lm.encoder.config.hidden_size\n","        self.qa_outputs = nn.Linear(self.hidden_size//2, self.lm.encoder.config.num_labels)\n","\n","    def forward(\n","            self,\n","            input_ids=None,\n","            attention_mask=None,\n","            token_type_ids=None,\n","            position_ids=None,\n","            head_mask=None,\n","            inputs_embeds=None,\n","            output_attentions=None,\n","            output_hidden_states=None,\n","            return_dict=None,\n","            adj_matrix=None,\n","    ):\n","        outputs = self.lm(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","        lm_output = outputs[0]\n","        \n","        #import pdb\n","        #pdb.set_trace()\n","\n","        #edge_index = [torch.transpose(adj_matrix[i][:,:2], 0,1) for i in range(len(adj_matrix)-1)]\n","        #edge_type = [torch.transpose(adj_matrix[i][:,2], 0,1) for i in range(len(adj_matrix)-1)]\n","        edge_index = torch.transpose(adj_matrix[0][:, :2], 0, 1)\n","        edge_type = torch.tensor(adj_matrix[0][:, 2])\n","        \n","        features_x = torch.tensor(normalized_embeddings) #torch.tensor([normalized_embeddings[i] for i in input_ids[0]])\n","        \n","        #edge_index, _ = batch_graph(edge_index, edge_type, 200)\n","        \n","        edge_index = edge_index.long()\n","        \n","        gnn_output = self.gnn(features_x, edge_index)#*0\n","        #gnn_output = gnn_output.unsqueeze(0)\n","\n","        import pdb\n","        pdb.set_trace()\n","\n","        lm_output = lm_output.squeeze()\n","\n","        sequence_output = torch.cat([lm_output, gnn_output]) if self.gnn_present else lm_output\n","        logits = self.qa_outputs(sequence_output)\n","        start_logits, end_logits = logits.split(1, dim=-1)\n","        start_logits = start_logits.squeeze(-1).contiguous()\n","        end_logits = end_logits.squeeze(-1).contiguous()\n","\n","        return QuestionAnsweringModelOutput(\n","            start_logits=start_logits,\n","            end_logits=end_logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nseozvJQ2Bc"},"source":["def loss_compute(start_positions, end_positions, start_logits, end_logits):\n","    total_loss = None\n","    import pdb\n","    pdb.set_trace()\n","    if start_positions is not None and end_positions is not None:\n","        # If we are on multi-GPU, split add a dimension\n","        if len(start_positions.size()) > 1:\n","            start_positions = start_positions.squeeze(-1)\n","        if len(end_positions.size()) > 1:\n","            end_positions = end_positions.squeeze(-1)\n","        # sometimes the start/end positions are outside our model inputs, we ignore these terms\n","        import pdb\n","        pdb.set_trace()\n","        ignored_index = start_logits.size(1)\n","        start_positions = start_positions.clamp(0, ignored_index)\n","        end_positions = end_positions.clamp(0, ignored_index)\n","\n","        loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n","        start_loss = loss_fct(start_logits, start_positions)\n","        end_loss = loss_fct(end_logits, end_positions)\n","        total_loss = (start_loss + end_loss) / 2\n","    return total_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5GZ7GU7HRBGy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639367976075,"user_tz":300,"elapsed":1259,"user":{"displayName":"Julsoles","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQsyPnEHtcIJ8Tllqntz58p0iz1ENQv8ftkloycg=s64","userId":"05704841641291254475"}},"outputId":"0a030e60-8462-4a32-cb09-1d991f0f0e75"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device = \"cpu\"\n","qamodel = AlbertQA(gnn_present=True)\n","qamodel.to(device)\n","optimizer = optim.Adam(qamodel.parameters(), lr=5e-5, weight_decay=0.001)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.dense.weight', 'predictions.decoder.bias', 'predictions.dense.bias', 'predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.weight']\n","- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"AxMB6qXCOwxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yb--PLw-y8DE"},"source":["import matplotlib.pyplot as plt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yuIwp9zSQ84D"},"source":["train_losses = []\n","test_losses = []\n","n_epochs = 5\n","for epoch in range(n_epochs):\n","    running_loss = 0\n","    n_correct = 0\n","    qamodel.train()\n","    for batch in tqdm(train_dataloader, leave=False):\n","        torch.cuda.empty_cache()\n","        input_ids = torch.stack(list(batch[0]), dim=0).to(device)\n","        attention_mask = torch.stack(list(batch[2]), dim=0).to(device)\n","        token_type_ids = torch.stack(list(batch[1]), dim=0).to(device)\n","\n","        start_positions = torch.stack(list(batch[4]), dim=0).to(device)\n","        end_positions = torch.stack(list(batch[5]), dim=0).to(device)\n","        out = qamodel(input_ids=input_ids,\n","                      attention_mask=attention_mask,\n","                      token_type_ids=token_type_ids,\n","                      adj_matrix=batch[3],\n","                      )\n","\n","        loss = loss_compute(start_positions, end_positions, out['start_logits'], out['end_logits'])\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        running_loss += loss.cpu().item()\n","    train_losses.append(running_loss / len(train_ds))\n","\n","    running_loss = 0\n","    with torch.no_grad():\n","        qamodel.eval()\n","        for batch in tqdm(val_dataloader, leave=False):\n","            input_ids = torch.stack(list(batch[0]), dim=0).to(device)\n","            attention_mask = torch.stack(list(batch[2]), dim=0).to(device)\n","            token_type_ids = torch.stack(list(batch[1]), dim=0).to(device)\n","\n","            start_positions = torch.stack(list(batch[4]), dim=0).to(device)\n","            end_positions = torch.stack(list(batch[5]), dim=0).to(device)\n","            out = qamodel(input_ids=input_ids,\n","                        attention_mask=attention_mask,\n","                        token_type_ids=token_type_ids,\n","                        adj_matrix=batch[3],\n","                        )\n","\n","            loss = loss_compute(start_positions, end_positions, out['start_logits'], out['end_logits'])\n","            running_loss += loss.cpu().item()\n","\n","    test_losses.append(running_loss / len(val_ds))\n","\n","    print(\"=\" * 20)\n","    print(f\"Epoch {epoch + 1}/{n_epochs} Train Loss: {running_loss / len(train_ds)}\")\n","    print(f\"Epoch {epoch+1}/{n_epochs} Test Loss: {running_loss / len(val_ds)}\")\n","\n","plt.plot(train_losses, label=\"train\")\n","plt.plot(test_losses, label=\"test\")\n","plt.legend()\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"mean loss\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(train_losses, label=\"train\")\n","# plt.plot(test_losses, label=\"test\")\n","plt.legend()\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"mean loss\")\n","plt.show()"],"metadata":{"id":"rPWvhsxn6Rl8"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-TobsNi5oFb7"},"source":["torch.save(qamodel.state_dict(), 'albertqa_nognn_1.mdl')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqpJyr5wLnfh","executionInfo":{"status":"ok","timestamp":1639348548065,"user_tz":480,"elapsed":987,"user":{"displayName":"Nima Farrokhsiar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjUN-jk3sxScMOH0Yz7zeyqeLSTgMdH9EHg1BTfWQ=s64","userId":"14506066315870311515"}},"outputId":"01a13bca-d8ba-4cec-9e78-69c0446a5784"},"source":["model = AlbertQA()\n","model.load_state_dict(torch.load('albertqa_nognn_1.mdl'))\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.bias', 'predictions.dense.weight']\n","- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["AlbertQA(\n","  (lm): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (attention_dropout): Dropout(p=0, inplace=False)\n","                (output_dropout): Dropout(p=0, inplace=False)\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n","              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n","              (dropout): Dropout(p=0, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=768, out_features=768, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (gnn): Linear(in_features=768, out_features=768, bias=True)\n","  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"KpS61UtHoFcA"},"source":[""],"execution_count":null,"outputs":[]}]}